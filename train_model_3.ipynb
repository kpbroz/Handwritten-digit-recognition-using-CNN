{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4586b1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "print('Importing the libraries')\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# \n",
    "print('Part 1 - Data Preprocessing')\n",
    "\n",
    "# Preprocessing the Training set\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)\n",
    "\n",
    "training_set = train_datagen.flow_from_directory('dataset1/train_set',\n",
    "                                                 color_mode=\"grayscale\",\n",
    "                                                 target_size = (28, 28),\n",
    "                                                 batch_size = 32,\n",
    "                                                 class_mode = 'categorical')\n",
    "\n",
    "# \n",
    "print('Preprocessing the Test set')\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "test_set = test_datagen.flow_from_directory('dataset1/test_set',\n",
    "                                            color_mode=\"grayscale\",\n",
    "                                            target_size = (28, 28),\n",
    "                                            batch_size = 32,\n",
    "                                            class_mode = 'categorical')\n",
    "\n",
    "\n",
    "# \n",
    "print('Part 2 - Building the CNN')\n",
    "\n",
    "# \n",
    "print('Initialising the CNN')\n",
    "cnn = tf.keras.models.Sequential()\n",
    "\n",
    "# \n",
    "print('Step 1 - Convolution')\n",
    "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=(3,3), activation='relu', input_shape=(28, 28, 1)))\n",
    "\n",
    "# \n",
    "print('Step 2 - Pooling')\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))\n",
    "\n",
    "# \n",
    "print('Adding a second convolutional layer')\n",
    "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu'))\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))\n",
    "\n",
    "# \n",
    "print('Step 3 - Flattening')\n",
    "cnn.add(tf.keras.layers.Flatten())\n",
    "\n",
    "# \n",
    "print('Step 4 - Full Connection')\n",
    "cnn.add(tf.keras.layers.Dense(units=128, activation='relu'))\n",
    "\n",
    "cnn.add(tf.keras.layers.Dense(units=64, activation='relu'))\n",
    "\n",
    "# \n",
    "print('Step 5 - Output Layer')\n",
    "cnn.add(tf.keras.layers.Dense(units=10, activation='softmax'))\n",
    "\n",
    "\n",
    "# \n",
    "print('Part 3 - Training the CNN')\n",
    "\n",
    "# \n",
    "print('Compiling the CNN')\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=1e-4)\n",
    "cnn.compile(optimizer = opt, loss = 'categorical_crossentropy', metrics = [\"accuracy\"])\n",
    "\n",
    "# \n",
    "print('Training the CNN on the Training set and evaluating it on the Test set')\n",
    "cnn.fit(x=training_set,validation_data=test_set, epochs=5)\n",
    "\n",
    "\n",
    "\n",
    "cnn.save('mnist.h5')\n",
    "print(\"Saving the model as mnist1.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "360416a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing the libraries\n",
      "Part 1 - Data Preprocessing\n",
      "Found 9997 images belonging to 10 classes.\n",
      "Preprocessing the Test set\n",
      "Found 270 images belonging to 10 classes.\n",
      "Part 2 - Building the CNN\n",
      "Initialising the CNN\n",
      "Step 1 - Convolution\n",
      "Step 2 - Pooling\n",
      "Adding a second convolutional layer\n",
      "Step 3 - Flattening\n",
      "Step 4 - Full Connection\n",
      "Step 5 - Output Layer\n",
      "Part 3 - Training the CNN\n",
      "Compiling the CNN\n",
      "Training the CNN on the Training set and evaluating it on the Test set\n",
      "Epoch 1/32\n",
      "313/313 [==============================] - 8s 24ms/step - loss: 2.1813 - accuracy: 0.3101 - val_loss: 1.9307 - val_accuracy: 0.4778\n",
      "Epoch 2/32\n",
      "313/313 [==============================] - 7s 24ms/step - loss: 1.3739 - accuracy: 0.6158 - val_loss: 1.3773 - val_accuracy: 0.5519\n",
      "Epoch 3/32\n",
      "313/313 [==============================] - 7s 22ms/step - loss: 0.9802 - accuracy: 0.7049 - val_loss: 1.2099 - val_accuracy: 0.6481\n",
      "Epoch 4/32\n",
      "313/313 [==============================] - 7s 21ms/step - loss: 0.8420 - accuracy: 0.7450 - val_loss: 1.1554 - val_accuracy: 0.6444\n",
      "Epoch 5/32\n",
      "313/313 [==============================] - 7s 23ms/step - loss: 0.7465 - accuracy: 0.7766 - val_loss: 1.0858 - val_accuracy: 0.6815\n",
      "Epoch 6/32\n",
      "313/313 [==============================] - 7s 23ms/step - loss: 0.6794 - accuracy: 0.7976 - val_loss: 1.0823 - val_accuracy: 0.6593\n",
      "Epoch 7/32\n",
      "313/313 [==============================] - 7s 22ms/step - loss: 0.6197 - accuracy: 0.8182 - val_loss: 0.9831 - val_accuracy: 0.7037\n",
      "Epoch 8/32\n",
      "313/313 [==============================] - 7s 22ms/step - loss: 0.5692 - accuracy: 0.8298 - val_loss: 0.9384 - val_accuracy: 0.7333\n",
      "Epoch 9/32\n",
      "313/313 [==============================] - 7s 23ms/step - loss: 0.5219 - accuracy: 0.8457 - val_loss: 0.9059 - val_accuracy: 0.7222\n",
      "Epoch 10/32\n",
      "313/313 [==============================] - 7s 22ms/step - loss: 0.4811 - accuracy: 0.8577 - val_loss: 0.8574 - val_accuracy: 0.7444\n",
      "Epoch 11/32\n",
      "313/313 [==============================] - 7s 23ms/step - loss: 0.4457 - accuracy: 0.8739 - val_loss: 0.8309 - val_accuracy: 0.7556\n",
      "Epoch 12/32\n",
      "313/313 [==============================] - 8s 24ms/step - loss: 0.4129 - accuracy: 0.8804 - val_loss: 0.7804 - val_accuracy: 0.7444\n",
      "Epoch 13/32\n",
      "313/313 [==============================] - 8s 24ms/step - loss: 0.3848 - accuracy: 0.8885 - val_loss: 0.7650 - val_accuracy: 0.7667\n",
      "Epoch 14/32\n",
      "313/313 [==============================] - 8s 24ms/step - loss: 0.3605 - accuracy: 0.8954 - val_loss: 0.7323 - val_accuracy: 0.7852\n",
      "Epoch 15/32\n",
      "313/313 [==============================] - 8s 24ms/step - loss: 0.3393 - accuracy: 0.9006 - val_loss: 0.7067 - val_accuracy: 0.8037\n",
      "Epoch 16/32\n",
      "313/313 [==============================] - 8s 25ms/step - loss: 0.3201 - accuracy: 0.9069 - val_loss: 0.6592 - val_accuracy: 0.7963\n",
      "Epoch 17/32\n",
      "313/313 [==============================] - 8s 24ms/step - loss: 0.3004 - accuracy: 0.9144 - val_loss: 0.6285 - val_accuracy: 0.8185\n",
      "Epoch 18/32\n",
      "313/313 [==============================] - 8s 25ms/step - loss: 0.2856 - accuracy: 0.9173 - val_loss: 0.6031 - val_accuracy: 0.8444\n",
      "Epoch 19/32\n",
      "313/313 [==============================] - 8s 24ms/step - loss: 0.2703 - accuracy: 0.9214 - val_loss: 0.6138 - val_accuracy: 0.8148\n",
      "Epoch 20/32\n",
      "313/313 [==============================] - 8s 25ms/step - loss: 0.2581 - accuracy: 0.9267 - val_loss: 0.6072 - val_accuracy: 0.8111\n",
      "Epoch 21/32\n",
      "313/313 [==============================] - 8s 25ms/step - loss: 0.2454 - accuracy: 0.9308 - val_loss: 0.5875 - val_accuracy: 0.8259\n",
      "Epoch 22/32\n",
      "313/313 [==============================] - 8s 24ms/step - loss: 0.2344 - accuracy: 0.9327 - val_loss: 0.5478 - val_accuracy: 0.8370\n",
      "Epoch 23/32\n",
      "313/313 [==============================] - 8s 24ms/step - loss: 0.2236 - accuracy: 0.9368 - val_loss: 0.5238 - val_accuracy: 0.8556\n",
      "Epoch 24/32\n",
      "313/313 [==============================] - 8s 24ms/step - loss: 0.2138 - accuracy: 0.9391 - val_loss: 0.5364 - val_accuracy: 0.8407\n",
      "Epoch 25/32\n",
      "313/313 [==============================] - 8s 25ms/step - loss: 0.2069 - accuracy: 0.9409 - val_loss: 0.5572 - val_accuracy: 0.8333\n",
      "Epoch 26/32\n",
      "313/313 [==============================] - ETA: 0s - loss: 0.2007 - accuracy: 0.94 - 8s 25ms/step - loss: 0.2007 - accuracy: 0.9428 - val_loss: 0.4874 - val_accuracy: 0.8444\n",
      "Epoch 27/32\n",
      "313/313 [==============================] - 8s 24ms/step - loss: 0.1906 - accuracy: 0.9476 - val_loss: 0.4954 - val_accuracy: 0.8444\n",
      "Epoch 28/32\n",
      "313/313 [==============================] - 8s 25ms/step - loss: 0.1827 - accuracy: 0.9492 - val_loss: 0.4519 - val_accuracy: 0.8593\n",
      "Epoch 29/32\n",
      "313/313 [==============================] - 8s 25ms/step - loss: 0.1744 - accuracy: 0.9507 - val_loss: 0.4509 - val_accuracy: 0.8704\n",
      "Epoch 30/32\n",
      "313/313 [==============================] - 8s 25ms/step - loss: 0.1672 - accuracy: 0.9537 - val_loss: 0.4398 - val_accuracy: 0.8630\n",
      "Epoch 31/32\n",
      "313/313 [==============================] - 8s 25ms/step - loss: 0.1632 - accuracy: 0.9531 - val_loss: 0.4447 - val_accuracy: 0.8593\n",
      "Epoch 32/32\n",
      "313/313 [==============================] - 8s 24ms/step - loss: 0.1585 - accuracy: 0.9555 - val_loss: 0.4616 - val_accuracy: 0.8704\n",
      "Saving the model as model_grayscale_3.h5\n"
     ]
    }
   ],
   "source": [
    "# GRAYSCALE without ImageDataGenerate- 32 epochs\n",
    "#model-3\n",
    "\n",
    "print('Importing the libraries')\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# \n",
    "print('Part 1 - Data Preprocessing')\n",
    "\n",
    "# Preprocessing the Training set\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "'''\n",
    ",\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)'''\n",
    "\n",
    "#train_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "training_set = train_datagen.flow_from_directory('train_set',\n",
    "                                                 color_mode=\"grayscale\",\n",
    "                                                 target_size = (28, 28),\n",
    "                                                 batch_size = 32,\n",
    "                                                 class_mode = 'categorical')\n",
    "\n",
    "# \n",
    "print('Preprocessing the Test set')\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "test_set = test_datagen.flow_from_directory('test_set',\n",
    "                                            color_mode=\"grayscale\",\n",
    "                                            target_size = (28, 28),\n",
    "                                            batch_size = 32,\n",
    "                                            class_mode = 'categorical')\n",
    "\n",
    "\n",
    "# \n",
    "print('Part 2 - Building the CNN')\n",
    "\n",
    "# \n",
    "print('Initialising the CNN')\n",
    "cnn = tf.keras.models.Sequential()\n",
    "\n",
    "# \n",
    "print('Step 1 - Convolution')\n",
    "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=(3,3), activation='relu', input_shape=(28, 28, 1)))\n",
    "\n",
    "# \n",
    "print('Step 2 - Pooling')\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))\n",
    "\n",
    "# \n",
    "print('Adding a second convolutional layer')\n",
    "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu'))\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))\n",
    "\n",
    "# \n",
    "print('Step 3 - Flattening')\n",
    "cnn.add(tf.keras.layers.Flatten())\n",
    "\n",
    "# \n",
    "print('Step 4 - Full Connection')\n",
    "cnn.add(tf.keras.layers.Dense(units=128, activation='relu'))\n",
    "\n",
    "# \n",
    "print('Step 5 - Output Layer')\n",
    "cnn.add(tf.keras.layers.Dense(units=10, activation='softmax'))\n",
    "\n",
    "\n",
    "# \n",
    "print('Part 3 - Training the CNN')\n",
    "\n",
    "# \n",
    "print('Compiling the CNN')\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=1e-4)\n",
    "cnn.compile(optimizer = opt, loss = 'categorical_crossentropy', metrics = [\"accuracy\"])\n",
    "\n",
    "# \n",
    "print('Training the CNN on the Training set and evaluating it on the Test set')\n",
    "cnn.fit(x=training_set,validation_data=test_set, epochs=32)\n",
    "\n",
    "\n",
    "\n",
    "cnn.save('model_grayscale_3.h5')\n",
    "print(\"Saving the model as model_grayscale_3.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7e67016",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing import image\n",
    "cnn=load_model('model_grayscale_3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ebc0c7fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "test_image = image.load_img('1_156.jpg', target_size = (28,28))\n",
    "test_image=test_image.convert('L')\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "result = cnn.predict(test_image)\n",
    "training_set.class_indices\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b44a187a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "test_image = image.load_img('9_86.jpg', target_size = (28,28))\n",
    "test_image=test_image.convert('L')\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "result = cnn.predict(test_image)\n",
    "training_set.class_indices\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b4af6d88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "test_image = image.load_img('two1.jfif', target_size = (28,28))\n",
    "test_image=test_image.convert('L')\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "result = cnn.predict(test_image)\n",
    "training_set.class_indices\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "46885024",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "test_image = image.load_img('three.jpg', target_size = (28,28))\n",
    "test_image=test_image.convert('L')\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "result = cnn.predict(test_image)\n",
    "training_set.class_indices\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "736ca686",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
