{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "20e484e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing the libraries\n",
      "Part 1 - Data Preprocessing\n",
      "Found 9997 images belonging to 10 classes.\n",
      "Preprocessing the Test set\n",
      "Found 270 images belonging to 10 classes.\n",
      "Part 2 - Building the CNN\n",
      "Initialising the CNN\n",
      "Step 1 - Convolution\n",
      "Step 2 - Pooling\n",
      "Adding a second convolutional layer\n",
      "Step 3 - Flattening\n",
      "Step 4 - Full Connection\n",
      "Step 5 - Output Layer\n",
      "Part 3 - Training the CNN\n",
      "Compiling the CNN\n",
      "Training the CNN on the Training set and evaluating it on the Test set\n",
      "Epoch 1/32\n",
      "313/313 [==============================] - 12s 36ms/step - loss: 2.2421 - accuracy: 0.2284 - val_loss: 2.1813 - val_accuracy: 0.3074 - loss: 2.2549 - accuracy: 0.21 - ETA: 1s - loss: 2.2544 - accura - ETA: 0s -\n",
      "Epoch 2/32\n",
      "313/313 [==============================] - 11s 36ms/step - loss: 1.8402 - accuracy: 0.4413 - val_loss: 1.8324 - val_accuracy: 0.4407 loss: 1.9583 - ac - ETA: 4s - loss: - ETA: 3s - loss: 1.9228 - ac - ETA: 2s - - ETA:  - ETA: 0s - loss: 1.8529 - ac\n",
      "Epoch 3/32\n",
      "313/313 [==============================] - 12s 37ms/step - loss: 1.3965 - accuracy: 0.5743 - val_loss: 1.5919 - val_accuracy: 0.5185\n",
      "Epoch 4/32\n",
      "313/313 [==============================] - 12s 37ms/step - loss: 1.2017 - accuracy: 0.6251 - val_loss: 1.4555 - val_accuracy: 0.5963\n",
      "Epoch 5/32\n",
      "313/313 [==============================] - 12s 37ms/step - loss: 1.0775 - accuracy: 0.6703 - val_loss: 1.3738 - val_accuracy: 0.6259\n",
      "Epoch 6/32\n",
      "313/313 [==============================] - 12s 38ms/step - loss: 0.9784 - accuracy: 0.6976 - val_loss: 1.2813 - val_accuracy: 0.6593\n",
      "Epoch 7/32\n",
      "313/313 [==============================] - 12s 37ms/step - loss: 0.8899 - accuracy: 0.7276 - val_loss: 1.2493 - val_accuracy: 0.6556\n",
      "Epoch 8/32\n",
      "313/313 [==============================] - 12s 38ms/step - loss: 0.8277 - accuracy: 0.7471 - val_loss: 1.1683 - val_accuracy: 0.6593\n",
      "Epoch 9/32\n",
      "313/313 [==============================] - 11s 36ms/step - loss: 0.7650 - accuracy: 0.7669 - val_loss: 1.0665 - val_accuracy: 0.6889\n",
      "Epoch 10/32\n",
      "313/313 [==============================] - 12s 37ms/step - loss: 0.7184 - accuracy: 0.7847 - val_loss: 1.0624 - val_accuracy: 0.6667\n",
      "Epoch 11/32\n",
      "313/313 [==============================] - 12s 37ms/step - loss: 0.6649 - accuracy: 0.7963 - val_loss: 0.9798 - val_accuracy: 0.7000\n",
      "Epoch 12/32\n",
      "313/313 [==============================] - 12s 37ms/step - loss: 0.6302 - accuracy: 0.8089 - val_loss: 0.9398 - val_accuracy: 0.7222\n",
      "Epoch 13/32\n",
      "313/313 [==============================] - 11s 37ms/step - loss: 0.5864 - accuracy: 0.8203 - val_loss: 0.8869 - val_accuracy: 0.7259acy - ETA: 6s - loss: 0.6118 - accuracy:  - ETA: 5s - loss: 0.6087 - accuracy: 0.81 - ETA: 5s - loss: 0 - ETA: 3s - loss: 0.5937 - accuracy:  - ETA: 3s - loss: 0 - ETA: 2s - loss: 0.5930 - accu - ETA: 1s - loss: 0.5910 - \n",
      "Epoch 14/32\n",
      "313/313 [==============================] - 12s 37ms/step - loss: 0.5562 - accuracy: 0.8322 - val_loss: 0.8877 - val_accuracy: 0.7333\n",
      "Epoch 15/32\n",
      "313/313 [==============================] - 12s 38ms/step - loss: 0.5328 - accuracy: 0.8365 - val_loss: 0.8910 - val_accuracy: 0.7148\n",
      "Epoch 16/32\n",
      "313/313 [==============================] - 11s 37ms/step - loss: 0.5208 - accuracy: 0.8444 - val_loss: 0.8102 - val_accuracy: 0.7370\n",
      "Epoch 17/32\n",
      "313/313 [==============================] - 12s 38ms/step - loss: 0.4925 - accuracy: 0.8506 - val_loss: 0.7873 - val_accuracy: 0.7333.5028 - accura - ETA: 1s - loss: 0.5023 - accuracy: 0. - ETA: 1s - loss: 0.5020 -  - ETA: 1s - l\n",
      "Epoch 18/32\n",
      "313/313 [==============================] - 12s 38ms/step - loss: 0.4749 - accuracy: 0.8547 - val_loss: 0.7727 - val_accuracy: 0.7481\n",
      "Epoch 19/32\n",
      "313/313 [==============================] - 12s 37ms/step - loss: 0.4507 - accuracy: 0.8614 - val_loss: 0.7490 - val_accuracy: 0.7556\n",
      "Epoch 20/32\n",
      "313/313 [==============================] - 12s 37ms/step - loss: 0.4369 - accuracy: 0.8662 - val_loss: 0.7148 - val_accuracy: 0.7667: 0.86 - ETA: 1s - ETA: 0s - loss: 0.4405 \n",
      "Epoch 21/32\n",
      "313/313 [==============================] - 12s 37ms/step - loss: 0.4211 - accuracy: 0.8727 - val_loss: 0.7130 - val_accuracy: 0.7704\n",
      "Epoch 22/32\n",
      "313/313 [==============================] - 12s 38ms/step - loss: 0.4111 - accuracy: 0.8778 - val_loss: 0.7204 - val_accuracy: 0.7630\n",
      "Epoch 23/32\n",
      "313/313 [==============================] - 12s 37ms/step - loss: 0.3994 - accuracy: 0.8807 - val_loss: 0.6995 - val_accuracy: 0.7815\n",
      "Epoch 24/32\n",
      "313/313 [==============================] - 12s 37ms/step - loss: 0.3892 - accuracy: 0.8818 - val_loss: 0.7467 - val_accuracy: 0.7556\n",
      "Epoch 25/32\n",
      "313/313 [==============================] - 12s 37ms/step - loss: 0.3767 - accuracy: 0.8860 - val_loss: 0.6736 - val_accuracy: 0.7778\n",
      "Epoch 26/32\n",
      "313/313 [==============================] - 12s 38ms/step - loss: 0.3652 - accuracy: 0.8876 - val_loss: 0.6515 - val_accuracy: 0.8000 loss: 0.3\n",
      "Epoch 27/32\n",
      "313/313 [==============================] - 12s 38ms/step - loss: 0.3532 - accuracy: 0.8933 - val_loss: 0.6599 - val_accuracy: 0.7926\n",
      "Epoch 28/32\n",
      "313/313 [==============================] - 11s 37ms/step - loss: 0.3466 - accuracy: 0.8914 - val_loss: 0.7008 - val_accuracy: 0.76300.\n",
      "Epoch 29/32\n",
      "313/313 [==============================] - 12s 37ms/step - loss: 0.3440 - accuracy: 0.8948 - val_loss: 0.6054 - val_accuracy: 0.7926\n",
      "Epoch 30/32\n",
      "313/313 [==============================] - 12s 38ms/step - loss: 0.3326 - accuracy: 0.8972 - val_loss: 0.6163 - val_accuracy: 0.8074\n",
      "Epoch 31/32\n",
      "313/313 [==============================] - 12s 38ms/step - loss: 0.3244 - accuracy: 0.9015 - val_loss: 0.5880 - val_accuracy: 0.7963\n",
      "Epoch 32/32\n",
      "313/313 [==============================] - 12s 38ms/step - loss: 0.3238 - accuracy: 0.8989 - val_loss: 0.5897 - val_accuracy: 0.8000\n",
      "Saving the model as model_RGB.h5\n"
     ]
    }
   ],
   "source": [
    "# RGB IMAGE\n",
    "\n",
    "print('Importing the libraries')\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# \n",
    "print('Part 1 - Data Preprocessing')\n",
    "\n",
    "# Preprocessing the Training set\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)\n",
    "\n",
    "#train_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "training_set = train_datagen.flow_from_directory('train_set',\n",
    "                                                 target_size = (28, 28),\n",
    "                                                 batch_size = 32,\n",
    "                                                 class_mode = 'categorical')\n",
    "\n",
    "# \n",
    "print('Preprocessing the Test set')\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "test_set = test_datagen.flow_from_directory('test_set',\n",
    "                                            target_size = (28, 28),\n",
    "                                            batch_size = 32,\n",
    "                                            class_mode = 'categorical')\n",
    "\n",
    "\n",
    "# \n",
    "print('Part 2 - Building the CNN')\n",
    "\n",
    "# \n",
    "print('Initialising the CNN')\n",
    "cnn = tf.keras.models.Sequential()\n",
    "\n",
    "# \n",
    "print('Step 1 - Convolution')\n",
    "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu', input_shape=(28, 28, 3)))\n",
    "\n",
    "# \n",
    "print('Step 2 - Pooling')\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))\n",
    "\n",
    "# \n",
    "print('Adding a second convolutional layer')\n",
    "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu'))\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))\n",
    "\n",
    "# \n",
    "print('Step 3 - Flattening')\n",
    "cnn.add(tf.keras.layers.Flatten())\n",
    "\n",
    "# \n",
    "print('Step 4 - Full Connection')\n",
    "cnn.add(tf.keras.layers.Dense(units=128, activation='relu'))\n",
    "\n",
    "# \n",
    "print('Step 5 - Output Layer')\n",
    "cnn.add(tf.keras.layers.Dense(units=10, activation='softmax'))\n",
    "\n",
    "\n",
    "# \n",
    "print('Part 3 - Training the CNN')\n",
    "\n",
    "# \n",
    "print('Compiling the CNN')\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=1e-4)\n",
    "cnn.compile(optimizer = opt, loss = 'categorical_crossentropy', metrics = [\"accuracy\"])\n",
    "\n",
    "# \n",
    "print('Training the CNN on the Training set and evaluating it on the Test set')\n",
    "cnn.fit(x=training_set,validation_data=test_set, epochs=32)\n",
    "\n",
    "\n",
    "cnn.save('model_RGB.h5')\n",
    "print(\"Saving the model as model_RGB.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fbd8f621",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing import image\n",
    "cnn=load_model('model_RGB.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aaed711b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "test_image = image.load_img('1_156.jpg', target_size = (28,28))\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "result = cnn.predict(test_image)\n",
    "training_set.class_indices\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bfcaadd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "test_image = image.load_img('9_86.jpg', target_size = (28,28))\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "result = cnn.predict(test_image)\n",
    "training_set.class_indices\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "915dab8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "test_image = image.load_img('9_52.jpg', target_size = (28,28))\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "result = cnn.predict(test_image)\n",
    "training_set.class_indices\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "aebe8072",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "test_image = image.load_img('three.jpg', target_size = (28,28))\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "result = cnn.predict(test_image)\n",
    "training_set.class_indices\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73a3f2c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
