{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1fab3afd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing the libraries\n",
      "Part 1 - Data Preprocessing\n",
      "Found 9997 images belonging to 10 classes.\n",
      "Preprocessing the Test set\n",
      "Found 270 images belonging to 10 classes.\n",
      "Part 2 - Building the CNN\n",
      "Initialising the CNN\n",
      "Step 1 - Convolution\n",
      "Step 2 - Pooling\n",
      "Adding a second convolutional layer\n",
      "Step 3 - Flattening\n",
      "Step 4 - Full Connection\n",
      "Step 5 - Output Layer\n",
      "Part 3 - Training the CNN\n",
      "Compiling the CNN\n",
      "Training the CNN on the Training set and evaluating it on the Test set\n",
      "Epoch 1/60\n",
      "313/313 [==============================] - 12s 36ms/step - loss: 2.2796 - accuracy: 0.1708 - val_loss: 2.2493 - val_accuracy: 0.17788 - accuracy - ETA: 0s - loss: 2.2803 - accuracy: 0.\n",
      "Epoch 2/60\n",
      "313/313 [==============================] - 10s 32ms/step - loss: 2.0383 - accuracy: 0.3686 - val_loss: 1.9472 - val_accuracy: 0.3407\n",
      "Epoch 3/60\n",
      "313/313 [==============================] - 9s 29ms/step - loss: 1.6183 - accuracy: 0.4900 - val_loss: 1.6705 - val_accuracy: 0.5000\n",
      "Epoch 4/60\n",
      "313/313 [==============================] - 9s 28ms/step - loss: 1.3606 - accuracy: 0.5754 - val_loss: 1.5586 - val_accuracy: 0.5778\n",
      "Epoch 5/60\n",
      "313/313 [==============================] - 9s 28ms/step - loss: 1.2232 - accuracy: 0.6213 - val_loss: 1.4796 - val_accuracy: 0.5926\n",
      "Epoch 6/60\n",
      "313/313 [==============================] - 9s 28ms/step - loss: 1.1280 - accuracy: 0.6533 - val_loss: 1.4086 - val_accuracy: 0.6148\n",
      "Epoch 7/60\n",
      "313/313 [==============================] - 9s 28ms/step - loss: 1.0416 - accuracy: 0.6814 - val_loss: 1.3417 - val_accuracy: 0.6370\n",
      "Epoch 8/60\n",
      "313/313 [==============================] - 9s 28ms/step - loss: 0.9664 - accuracy: 0.7025 - val_loss: 1.2942 - val_accuracy: 0.6407\n",
      "Epoch 9/60\n",
      "313/313 [==============================] - 9s 28ms/step - loss: 0.9045 - accuracy: 0.7239 - val_loss: 1.2155 - val_accuracy: 0.6667\n",
      "Epoch 10/60\n",
      "313/313 [==============================] - ETA: 0s - loss: 0.8517 - accuracy: 0.74 - 9s 28ms/step - loss: 0.8517 - accuracy: 0.7412 - val_loss: 1.1733 - val_accuracy: 0.6741\n",
      "Epoch 11/60\n",
      "313/313 [==============================] - 9s 28ms/step - loss: 0.8017 - accuracy: 0.7565 - val_loss: 1.1075 - val_accuracy: 0.6704\n",
      "Epoch 12/60\n",
      "313/313 [==============================] - 10s 32ms/step - loss: 0.7548 - accuracy: 0.7738 - val_loss: 1.0897 - val_accuracy: 0.6889\n",
      "Epoch 13/60\n",
      "313/313 [==============================] - 10s 32ms/step - loss: 0.7224 - accuracy: 0.7811 - val_loss: 1.0621 - val_accuracy: 0.6815\n",
      "Epoch 14/60\n",
      "313/313 [==============================] - 10s 31ms/step - loss: 0.6800 - accuracy: 0.7929 - val_loss: 1.0331 - val_accuracy: 0.6889\n",
      "Epoch 15/60\n",
      "313/313 [==============================] - 10s 31ms/step - loss: 0.6604 - accuracy: 0.8034 - val_loss: 1.0038 - val_accuracy: 0.6926\n",
      "Epoch 16/60\n",
      "313/313 [==============================] - 10s 31ms/step - loss: 0.6270 - accuracy: 0.8095 - val_loss: 0.9653 - val_accuracy: 0.7037\n",
      "Epoch 17/60\n",
      "313/313 [==============================] - 10s 31ms/step - loss: 0.6088 - accuracy: 0.8172 - val_loss: 0.9269 - val_accuracy: 0.7148\n",
      "Epoch 18/60\n",
      "313/313 [==============================] - 10s 32ms/step - loss: 0.5908 - accuracy: 0.8222 - val_loss: 0.8972 - val_accuracy: 0.7148\n",
      "Epoch 19/60\n",
      "313/313 [==============================] - 10s 32ms/step - loss: 0.5691 - accuracy: 0.8308 - val_loss: 0.8864 - val_accuracy: 0.70378 - accuracy\n",
      "Epoch 20/60\n",
      "313/313 [==============================] - 10s 31ms/step - loss: 0.5451 - accuracy: 0.8361 - val_loss: 0.8901 - val_accuracy: 0.7148\n",
      "Epoch 21/60\n",
      "313/313 [==============================] - 10s 31ms/step - loss: 0.5255 - accuracy: 0.8404 - val_loss: 0.8451 - val_accuracy: 0.7222\n",
      "Epoch 22/60\n",
      "313/313 [==============================] - 10s 32ms/step - loss: 0.5045 - accuracy: 0.8470 - val_loss: 0.8471 - val_accuracy: 0.7111\n",
      "Epoch 23/60\n",
      "313/313 [==============================] - 10s 32ms/step - loss: 0.4975 - accuracy: 0.8504 - val_loss: 0.8362 - val_accuracy: 0.7370\n",
      "Epoch 24/60\n",
      "313/313 [==============================] - 10s 31ms/step - loss: 0.4776 - accuracy: 0.8532 - val_loss: 0.8502 - val_accuracy: 0.7222\n",
      "Epoch 25/60\n",
      "313/313 [==============================] - 10s 31ms/step - loss: 0.4699 - accuracy: 0.8525 - val_loss: 0.7997 - val_accuracy: 0.7222\n",
      "Epoch 26/60\n",
      "313/313 [==============================] - 10s 31ms/step - loss: 0.4568 - accuracy: 0.8605 - val_loss: 0.8256 - val_accuracy: 0.7296\n",
      "Epoch 27/60\n",
      "313/313 [==============================] - 10s 31ms/step - loss: 0.4370 - accuracy: 0.8693 - val_loss: 0.7574 - val_accuracy: 0.7481\n",
      "Epoch 28/60\n",
      "313/313 [==============================] - 10s 33ms/step - loss: 0.4368 - accuracy: 0.8650 - val_loss: 0.7459 - val_accuracy: 0.7519- accura - ETA: \n",
      "Epoch 29/60\n",
      "313/313 [==============================] - 10s 32ms/step - loss: 0.4215 - accuracy: 0.8724 - val_loss: 0.7499 - val_accuracy: 0.7704\n",
      "Epoch 30/60\n",
      "313/313 [==============================] - 10s 31ms/step - loss: 0.4189 - accuracy: 0.8739 - val_loss: 0.7380 - val_accuracy: 0.7630\n",
      "Epoch 31/60\n",
      "313/313 [==============================] - 9s 28ms/step - loss: 0.4019 - accuracy: 0.8789 - val_loss: 0.7027 - val_accuracy: 0.7778\n",
      "Epoch 32/60\n",
      "313/313 [==============================] - 9s 28ms/step - loss: 0.3942 - accuracy: 0.8772 - val_loss: 0.6847 - val_accuracy: 0.7889\n",
      "Epoch 33/60\n",
      "313/313 [==============================] - 9s 29ms/step - loss: 0.3878 - accuracy: 0.8812 - val_loss: 0.6685 - val_accuracy: 0.8000\n",
      "Epoch 34/60\n",
      "313/313 [==============================] - 9s 29ms/step - loss: 0.3836 - accuracy: 0.8851 - val_loss: 0.6716 - val_accuracy: 0.7852\n",
      "Epoch 35/60\n",
      "313/313 [==============================] - 9s 29ms/step - loss: 0.3667 - accuracy: 0.8895 - val_loss: 0.6606 - val_accuracy: 0.7926\n",
      "Epoch 36/60\n",
      "313/313 [==============================] - 9s 30ms/step - loss: 0.3667 - accuracy: 0.8879 - val_loss: 0.6719 - val_accuracy: 0.7963\n",
      "Epoch 37/60\n",
      "313/313 [==============================] - 9s 29ms/step - loss: 0.3603 - accuracy: 0.8920 - val_loss: 0.6482 - val_accuracy: 0.7889\n",
      "Epoch 38/60\n",
      "313/313 [==============================] - 10s 31ms/step - loss: 0.3491 - accuracy: 0.8911 - val_loss: 0.6629 - val_accuracy: 0.8074 - loss: 0.3474 - accu\n",
      "Epoch 39/60\n",
      "313/313 [==============================] - 11s 34ms/step - loss: 0.3433 - accuracy: 0.8925 - val_loss: 0.6188 - val_accuracy: 0.8148\n",
      "Epoch 40/60\n",
      "313/313 [==============================] - 10s 32ms/step - loss: 0.3347 - accuracy: 0.9005 - val_loss: 0.6117 - val_accuracy: 0.7963\n",
      "Epoch 41/60\n",
      "313/313 [==============================] - 10s 32ms/step - loss: 0.3366 - accuracy: 0.8976 - val_loss: 0.6017 - val_accuracy: 0.8222\n",
      "Epoch 42/60\n",
      "313/313 [==============================] - 10s 32ms/step - loss: 0.3229 - accuracy: 0.9010 - val_loss: 0.5725 - val_accuracy: 0.8259\n",
      "Epoch 43/60\n",
      "313/313 [==============================] - 10s 33ms/step - loss: 0.3328 - accuracy: 0.8983 - val_loss: 0.5607 - val_accuracy: 0.8259\n",
      "Epoch 44/60\n",
      "313/313 [==============================] - 10s 33ms/step - loss: 0.3147 - accuracy: 0.9018 - val_loss: 0.6276 - val_accuracy: 0.8222\n",
      "Epoch 45/60\n",
      "313/313 [==============================] - 10s 32ms/step - loss: 0.3043 - accuracy: 0.9095 - val_loss: 0.6057 - val_accuracy: 0.8148\n",
      "Epoch 46/60\n",
      "313/313 [==============================] - 10s 32ms/step - loss: 0.3090 - accuracy: 0.9020 - val_loss: 0.5596 - val_accuracy: 0.8222\n",
      "Epoch 47/60\n",
      "313/313 [==============================] - 10s 32ms/step - loss: 0.2997 - accuracy: 0.9051 - val_loss: 0.5970 - val_accuracy: 0.8185\n",
      "Epoch 48/60\n",
      "313/313 [==============================] - 10s 32ms/step - loss: 0.2976 - accuracy: 0.9094 - val_loss: 0.5899 - val_accuracy: 0.8111\n",
      "Epoch 49/60\n",
      "313/313 [==============================] - 10s 32ms/step - loss: 0.2974 - accuracy: 0.9079 - val_loss: 0.5083 - val_accuracy: 0.8333\n",
      "Epoch 50/60\n",
      "313/313 [==============================] - 10s 32ms/step - loss: 0.2954 - accuracy: 0.9098 - val_loss: 0.5681 - val_accuracy: 0.8185\n",
      "Epoch 51/60\n",
      "313/313 [==============================] - 10s 33ms/step - loss: 0.2844 - accuracy: 0.9136 - val_loss: 0.5279 - val_accuracy: 0.8259\n",
      "Epoch 52/60\n",
      "313/313 [==============================] - 10s 32ms/step - loss: 0.2799 - accuracy: 0.9170 - val_loss: 0.5371 - val_accuracy: 0.82220.91\n",
      "Epoch 53/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 9s 30ms/step - loss: 0.2758 - accuracy: 0.9159 - val_loss: 0.5268 - val_accuracy: 0.8259\n",
      "Epoch 54/60\n",
      "313/313 [==============================] - 9s 30ms/step - loss: 0.2723 - accuracy: 0.9141 - val_loss: 0.5004 - val_accuracy: 0.8407\n",
      "Epoch 55/60\n",
      "313/313 [==============================] - 9s 30ms/step - loss: 0.2730 - accuracy: 0.9168 - val_loss: 0.4925 - val_accuracy: 0.8407\n",
      "Epoch 56/60\n",
      "313/313 [==============================] - 10s 31ms/step - loss: 0.2666 - accuracy: 0.9209 - val_loss: 0.4991 - val_accuracy: 0.8185\n",
      "Epoch 57/60\n",
      "313/313 [==============================] - 10s 31ms/step - loss: 0.2659 - accuracy: 0.9185 - val_loss: 0.4785 - val_accuracy: 0.8481\n",
      "Epoch 58/60\n",
      "313/313 [==============================] - 10s 31ms/step - loss: 0.2572 - accuracy: 0.9215 - val_loss: 0.5102 - val_accuracy: 0.8444\n",
      "Epoch 59/60\n",
      "313/313 [==============================] - 10s 31ms/step - loss: 0.2585 - accuracy: 0.9224 - val_loss: 0.4679 - val_accuracy: 0.8296\n",
      "Epoch 60/60\n",
      "313/313 [==============================] - 10s 32ms/step - loss: 0.2572 - accuracy: 0.9199 - val_loss: 0.4947 - val_accuracy: 0.8259\n",
      "Saving the model as model_grayscale_1.h5\n"
     ]
    }
   ],
   "source": [
    "# Grayscale with ImageDataGenerator- 60 epochs\n",
    "#model-1\n",
    "\n",
    "print('Importing the libraries')\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# \n",
    "print('Part 1 - Data Preprocessing')\n",
    "\n",
    "# Preprocessing the Training set\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)\n",
    "\n",
    "#train_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "training_set = train_datagen.flow_from_directory('train_set',\n",
    "                                                 color_mode=\"grayscale\",\n",
    "                                                 target_size = (28, 28),\n",
    "                                                 batch_size = 32,\n",
    "                                                 class_mode = 'categorical')\n",
    "\n",
    "# \n",
    "print('Preprocessing the Test set')\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "test_set = test_datagen.flow_from_directory('test_set',\n",
    "                                            color_mode=\"grayscale\",\n",
    "                                            target_size = (28, 28),\n",
    "                                            batch_size = 32,\n",
    "                                            class_mode = 'categorical')\n",
    "\n",
    "\n",
    "# \n",
    "print('Part 2 - Building the CNN')\n",
    "\n",
    "# \n",
    "print('Initialising the CNN')\n",
    "cnn = tf.keras.models.Sequential()\n",
    "\n",
    "# \n",
    "print('Step 1 - Convolution')\n",
    "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=(3,3), activation='relu', input_shape=(28, 28, 1)))\n",
    "\n",
    "# \n",
    "print('Step 2 - Pooling')\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))\n",
    "\n",
    "# \n",
    "print('Adding a second convolutional layer')\n",
    "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu'))\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))\n",
    "\n",
    "# \n",
    "print('Step 3 - Flattening')\n",
    "cnn.add(tf.keras.layers.Flatten())\n",
    "\n",
    "# \n",
    "print('Step 4 - Full Connection')\n",
    "cnn.add(tf.keras.layers.Dense(units=128, activation='relu'))\n",
    "\n",
    "# \n",
    "print('Step 5 - Output Layer')\n",
    "cnn.add(tf.keras.layers.Dense(units=10, activation='softmax'))\n",
    "\n",
    "\n",
    "# \n",
    "print('Part 3 - Training the CNN')\n",
    "\n",
    "# \n",
    "print('Compiling the CNN')\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=1e-4)\n",
    "cnn.compile(optimizer = opt, loss = 'categorical_crossentropy', metrics = [\"accuracy\"])\n",
    "\n",
    "# \n",
    "print('Training the CNN on the Training set and evaluating it on the Test set')\n",
    "cnn.fit(x=training_set,validation_data=test_set, epochs=60)\n",
    "\n",
    "\n",
    "\n",
    "cnn.save('model_grayscale_1.h5')\n",
    "print(\"Saving the model as model_grayscale_1.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a6c4976e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing import image\n",
    "cnn=load_model('model_grayscale_1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "14c65a7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "test_image = image.load_img('1_156.jpg', target_size = (28,28))\n",
    "test_image=test_image.convert('L')\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "result = cnn.predict(test_image)\n",
    "training_set.class_indices\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "88b58ed3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "test_image = image.load_img('9_86.jpg', target_size = (28,28))\n",
    "test_image=test_image.convert('L')\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "result = cnn.predict(test_image)\n",
    "training_set.class_indices\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9259d1d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "test_image = image.load_img('two1.jfif', target_size = (28,28))\n",
    "test_image=test_image.convert('L')\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "result = cnn.predict(test_image)\n",
    "training_set.class_indices\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "64ffe427",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "test_image = image.load_img('three.jpg', target_size = (28,28))\n",
    "test_image=test_image.convert('L')\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "result = cnn.predict(test_image)\n",
    "training_set.class_indices\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9849e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
